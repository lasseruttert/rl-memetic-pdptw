\begin{table}[htbp]
\centering
\caption{DQN Hyperparameter Tuning Results}
\label{tab:hp_tuning}
\begin{tabular}{llrrrr}
\toprule
Category & Value & Fitness & Std & Impr. & Time (s) \\
\midrule
  \multirow{4}{*}{Learning Rate} & 1e-3 & 1358.7 & 451.6 & +39958.3 & \textbf{0.39} \\
  & 5e-4 & 1344.5 & 459.5 & +39972.5 & 0.58 \\
  & 5e-5 & 1326.2 & 473.5 & +39990.8 & 0.67 \\
  & 1e-5 & \textbf{1323.3} & 467.0 & \textbf{+39993.7} & 0.64 \\
\midrule
  \multirow{3}{*}{Gamma (Î³)} & 0.99 & 1379.8 & 437.5 & +39937.2 & \textbf{0.40} \\
  & 0.95 & 1338.1 & 466.5 & +39978.9 & 0.74 \\
  & 0.85 & \textbf{1335.1} & 481.0 & \textbf{+39981.9} & 0.59 \\
\midrule
  \multirow{3}{*}{Epsilon Decay} & 0.999 & \textbf{1315.0} & 467.7 & \textbf{+40002.1} & 0.56 \\
  & 0.995 & 1333.4 & 469.2 & +39983.6 & \textbf{0.53} \\
  & 0.99 & 1317.2 & 469.5 & +39999.8 & 0.59 \\
\midrule
  \multirow{3}{*}{Batch Size} & 32 & \textbf{1316.3} & 471.6 & \textbf{+40000.7} & \textbf{0.59} \\
  & 128 & 1319.9 & 467.3 & +39997.2 & 0.80 \\
  & 256 & 1383.8 & 503.9 & +39933.2 & 0.61 \\
\midrule
  \multirow{3}{*}{N-step} & 1 & \textbf{1318.2} & 470.6 & \textbf{+39998.8} & \textbf{0.50} \\
  & 5 & 1323.5 & 473.6 & +39993.5 & 0.75 \\
  & 7 & 1333.2 & 477.9 & +39983.8 & 0.56 \\
\midrule
  \multirow{3}{*}{Target Update} & 25 & 1334.4 & 473.9 & +39982.6 & \textbf{0.57} \\
  & 50 & 1348.7 & 477.3 & +39968.3 & 0.59 \\
  & 200 & \textbf{1326.9} & 469.7 & \textbf{+39990.1} & 0.77 \\
\midrule
  \multirow{4}{*}{Network Architecture} & [64,64] & \textbf{1335.2} & 476.8 & \textbf{+39981.8} & 0.73 \\
  & [128,128,64]$^\ast$ & 1336.6 & 482.0 & +39980.4 & \textbf{0.49} \\
  & [256,128,64] & 1337.2 & 468.8 & +39979.8 & 0.54 \\
  & [256,256,128] & 1336.1 & 472.8 & +39980.9 & 0.70 \\
\bottomrule
\end{tabular}
\end{table}