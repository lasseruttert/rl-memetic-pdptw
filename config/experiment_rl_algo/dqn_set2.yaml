# Problem configuration
problem:
  size: 100
  categories: ['lc1', 'lc2', 'lr1', 'lr2']
  train_ratio: 0.8  # 80% train, 20% test split

# RL algorithm selection (dqn or ppo)
rl_algorithm: dqn

# Algorithm strategies
algorithm:
  acceptance_strategy: greedy  # greedy, always, epsilon_greedy, simulated_annealing, late_acceptance, rising_epsilon_greedy
  reward_strategy: binary      # binary, initial_improvement, old_improvement, hybrid_improvement, distance_baseline, log_improvement, tanh, component

# Network architecture
network:
  hidden_dims: [128, 128, 64]
  learning_rate: 0.0001  # 1e-4
  gamma: 0.90
  use_operator_attention: false

# DQN-specific parameters
dqn:
  epsilon_start: 1.0
  epsilon_end: 0.05
  epsilon_decay: 0.9975
  target_update_interval: 100
  batch_size: 64
  n_step: 3
  use_prioritized_replay: true
  per_alpha: 0.6
  per_beta_start: 0.4
  replay_buffer_capacity: 100000

# PPO-specific parameters (not used when rl_algorithm is dqn)
ppo:
  batch_size: 2048
  clip_epsilon: 0.2
  entropy_coef: 0.01
  num_epochs: 2
  num_minibatches: 2

# Training configuration
training:
  num_episodes: 1000
  max_iterations: 200
  max_no_improvement: 50
  warmup_episodes: 10
  save_interval: 1000
  new_instance_interval: 5
  new_solution_interval: 1
  update_interval: 1
  alpha: 10.0
  beta: 0.0
  seed: 100
  device: cuda
  verbose: true

# Validation configuration
validation:
  skip_validation: true
  mode: fixed_benchmark  # fixed_benchmark (reproducible) or random_sampled (faster)
  num_instances: 10
  interval: 50  # Evaluate every N episodes
  seeds: [42, 111, 222, 333, 444]
  runs_per_seed: 1

# Testing configuration
testing:
  skip_testing: false
  test_only: false
  num_test_problems: 50
  runs_per_problem: 3
  deterministic_test_rng: false
  test_seeds: [42, 422, 100, 200, 300]

# Operator configuration
operators:
  preset: custom  # standard, aggressive, minimal, cls, or custom
  custom:
    - type: Reinsert
      params: {}

    - type: Reinsert
      params:
        max_attempts: 5
        clustered: True

    - type: Reinsert
      params: 
        allow_same_vehicle: False   

    - type: Reinsert
      params: 
        allow_same_vehicle: False  
        allow_new_vehicles: False 
    
    - type: RouteElimination
      params: {}

    - type: TwoOpt
      params: {}

    - type: SwapBetween
      params: 
        type: best

    - type: Merge
      params: 
        type: min

    - type: CLSM2
      params: {}

    - type: CLSM3
      params: {}

    - type: CLSM4
      params: {}


# Path configuration (supports placeholders: {algorithm}, {problem_size}, {acceptance}, {reward}, {attention}, {seed}, {suffix}, {run_name})
paths:
  suffix: set2
  save_path: models/rl_local_search_{algorithm}_{problem_size}_{acceptance}_{reward}{attention}_{seed}_{suffix}
  tensorboard_dir: runs/{run_name}
  log_dir: logs
