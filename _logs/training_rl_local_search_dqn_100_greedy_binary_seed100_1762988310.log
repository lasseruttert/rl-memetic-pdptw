Logging to: logs/training_rl_local_search_dqn_100_greedy_binary_seed100_1762988310.log
================================================================================
Using Prioritized Replay Buffer (alpha=0.6, beta_start=0.4)
Algorithm: DQN
n-step returns: n=3
Operator Attention: DISABLED (standard concatenation)

Train/Test Split (ratio=0.8):
  lc1:
    Train (7): ['lc101', 'lc102', 'lc103', 'lc104', 'lc105', 'lc106', 'lc107']
    Test  (2): ['lc108', 'lc109']
  lc2:
    Train (6): ['lc201', 'lc202', 'lc203', 'lc204', 'lc205', 'lc206']
    Test  (2): ['lc207', 'lc208']
  lr1:
    Train (9): ['lr101', 'lr102', 'lr103', 'lr104', 'lr105', 'lr106', 'lr107', 'lr108', 'lr109']
    Test  (3): ['lr110', 'lr111', 'lr112']
  lr2:
    Train (8): ['lr201', 'lr202', 'lr203', 'lr204', 'lr205', 'lr206', 'lr207', 'lr208']
    Test  (3): ['lr209', 'lr210', 'lr211']


Validation Set:
  Mode: fixed_benchmark
  Instances: 10
  Seeds: [42, 111, 222, 333, 444]
  Runs per seed: 1
  Total runs per instance: 5
  Interval: 50 episodes

Starting RL Local Search Training on size 100 instances...
Algorithm: DQN
Categories: ['lc1', 'lc2', 'lr1', 'lr2']
Operator Attention: DISABLED
Random seed set to 100
PER beta will anneal from 0.4 to 1.0 over 200000 frames
TensorBoard logging enabled: runs/rl_local_search_dqn_100_greedy_binary_seed100_1762988310
Starting RL Local Search training for 1000 episodes...
State dim: 38, Action dim: 8
Operators: ['Reinsert-nC-Max1-NewV-SameV-nF_SameV', 'RouteElimination', 'Flip-Single-Unlimited', 'SwapWithin-random-A-MaxNone', 'SwapBetween-random', 'Transfer-A-Max1', 'Shift-random-A-Max3-Seg3-Dist5', 'TwoOpt']
Episode 0: New instance generated (55 requests)
Episode 0/1000 | Reward: -148.00 (avg: -148.00) | Fitness: 38504.21 (avg: 38504.21) | Steps: 200 | eps: 0.998 | Loss: 0.0000 | Time: 0.44s | Total: 0.46s
Episode 5: New instance generated (50 requests)


Training interrupted by user (Ctrl+C)
